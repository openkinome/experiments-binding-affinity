{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aa94cb0",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [10]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013137,
     "end_time": "2021-08-09T13:26:11.487442",
     "exception": false,
     "start_time": "2021-08-09T13:26:11.474305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train a model with PyTorch\n",
    "\n",
    "This notebooks trains a single model using only PyTorch.\n",
    "\n",
    "1. Tensors are loaded from Parquet files generated in the `features/` pipeline. Each Parquet becomes a Torch Dataset sublass.\n",
    "2. Random splits are applied for train/test/(val).\n",
    "3. It will train a single for model for a number of epochs across all datasets: epoch> dataloader> minibatch.\n",
    "4. The loss is computed through the `loss_adapter` method in each measurement_type.\n",
    "5. If validation is enabled, early stopping and LR schedulers are applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006512,
     "end_time": "2021-08-09T13:26:11.501586",
     "exception": false,
     "start_time": "2021-08-09T13:26:11.495074",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## How to use\n",
    "\n",
    "Run `python run_notebook.py --help` for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T13:26:11.518925Z",
     "iopub.status.busy": "2021-08-09T13:26:11.518361Z",
     "iopub.status.idle": "2021-08-09T13:26:11.520229Z",
     "shell.execute_reply": "2021-08-09T13:26:11.520620Z"
    },
    "papermill": {
     "duration": 0.013719,
     "end_time": "2021-08-09T13:26:11.520848",
     "exception": false,
     "start_time": "2021-08-09T13:26:11.507129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If this is the template file (and not a copy) and you are introducing changes,\n",
    "# update VERSION with the current date (YYYY.MM.DD)\n",
    "VERSION = \"2021.05.19\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005013,
     "end_time": "2021-08-09T13:26:11.531134",
     "exception": false,
     "start_time": "2021-08-09T13:26:11.526121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ‚úè Define hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T13:26:11.547374Z",
     "iopub.status.busy": "2021-08-09T13:26:11.546719Z",
     "iopub.status.idle": "2021-08-09T13:26:11.548941Z",
     "shell.execute_reply": "2021-08-09T13:26:11.549464Z"
    },
    "papermill": {
     "duration": 0.012973,
     "end_time": "2021-08-09T13:26:11.549623",
     "exception": false,
     "start_time": "2021-08-09T13:26:11.536650",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# TEMPLATE VALUES -- these are overriden (see below if executed) by papermill using a YAML or Python file as input\n",
    "\n",
    "# DATA -- Glob paths must be relative to the root of the repository: REPO / features\n",
    "PARQUET_LOADER_CLS = \"kinoml.datasets.torch_datasets.AwkwardArrayDataset\"\n",
    "PARQUET_FILES = [\n",
    "    \"path/to/*.parquet\",\n",
    "]\n",
    "\n",
    "# Model -- specified with the full import path to the class object\n",
    "## Machine learning model that will be trained. Pass it as importable string.\n",
    "MODEL_CLS = \"kinoml.ml.torch_models.NeuralNetworkRegression\"\n",
    "## Keyword arguments for the model initialization\n",
    "MODEL_KWARGS = {\"hidden_size\": 350}  # input_shape is defined dynamically during training\n",
    "\n",
    "# OPTIMIZER\n",
    "## Optimizer class. Pass it as an importable string.\n",
    "OPTIMIZER = \"torch.optim.Adam\"\n",
    "## Keyword arguments for the optimizer\n",
    "OPTIMIZER_KWARGS = {\"lr\": 0.001, \"eps\": 1e-7, \"betas\": [0.9, 0.999]}\n",
    "\n",
    "# LOSS FUNCTION\n",
    "## Loss function class. Pass it as an importable string.\n",
    "LOSS = \"torch.nn.MSELoss\"\n",
    "## Keyword arguments for the loss function, if applicable\n",
    "LOSS_KWARGS = {}\n",
    "\n",
    "# TRAINING\n",
    "## Maximum number of epochs the training will run. In practice it might be less due to early stopping\n",
    "MAX_EPOCHS = 50\n",
    "## Enable real-time validation: this will split the test set into two halves: test and validation.\n",
    "## It will also enable LR scheduling and early stopping, based on the validation loss.\n",
    "VALIDATION = True\n",
    "## Options for the builtin early stopper (kinoml.ml.torch_loops.EarlyStopping)\n",
    "EARLY_STOPPING_KWARGS = {}\n",
    "\n",
    "# DATALOADER\n",
    "DATALOADER_CLS = \"torch.utils.data.DataLoader\"  # you can also use torch_geometric.data.DataLoader\n",
    "## Minibatch size\n",
    "BATCH_SIZE = 64\n",
    "## Proportion of the dataset that will be split into a test set. If VALIDATION=True, \n",
    "## this will also cover the validation set. So, 0.2 will mean: 0.8 training, 0.1 test, 0.1 valid.\n",
    "TRAIN_TEST_SPLIT = 0.2\n",
    "## Whether to shuffle the indices before splitting\n",
    "SHUFFLE_SPLITS = True\n",
    "## Read https://pytorch.org/docs/stable/data.html#dataloader-collate-fn\n",
    "## IMPORTANT: This will be needed if your X tensors have different shapes across systems!\n",
    "COLLATE_FN = None\n",
    "\n",
    "# Plot bootstrapping\n",
    "## Bootstrapping iterations for the performance plots\n",
    "N_BOOTSTRAPS = 1\n",
    "## Proportion of the data that is sampled in each iteration\n",
    "BOOTSTRAP_SAMPLE_RATIO = 1\n",
    "\n",
    "# Output\n",
    "## Enable some extra output, like plots and logging statements.\n",
    "VERBOSE = False\n",
    "\n",
    "## IGNORE THIS ONE\n",
    "HERE = _dh[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be5d2570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T13:26:11.564365Z",
     "iopub.status.busy": "2021-08-09T13:26:11.563808Z",
     "iopub.status.idle": "2021-08-09T13:26:11.565722Z",
     "shell.execute_reply": "2021-08-09T13:26:11.566247Z"
    },
    "papermill": {
     "duration": 0.011639,
     "end_time": "2021-08-09T13:26:11.566413",
     "exception": false,
     "start_time": "2021-08-09T13:26:11.554774",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "PARQUET_FILES = [\n",
    "    \"ligand-only-graph-subsample/_output/ligand__SmilesToLigandFeaturizer__GraphLigandFeaturizer/ChEMBLDatasetProvider/*.parquet\"\n",
    "]\n",
    "MODEL_CLS = \"kinoml.ml.torch_geometric_models.GraphConvolutionNeuralNetwork\"\n",
    "MODEL_KWARGS = {}\n",
    "OPTIMIZER = \"torch.optim.Adam\"\n",
    "OPTIMIZER_KWARGS = {\"lr\": 0.001, \"eps\": 1e-07, \"betas\": [0.9, 0.999]}\n",
    "LOSS = \"torch.nn.MSELoss\"\n",
    "LOSS_KWARGS = {}\n",
    "MAX_EPOCHS = 50\n",
    "VALIDATION = True\n",
    "EARLY_STOPPING_KWARGS = {}\n",
    "DATALOADER_CLS = \"torch_geometric.data.DataLoader\"\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_TEST_SPLIT = 0.2\n",
    "SHUFFLE_SPLITS = True\n",
    "COLLATE_FN = None\n",
    "N_BOOTSTRAPS = 1\n",
    "BOOTSTRAP_SAMPLE_RATIO = 1\n",
    "VERBOSE = False\n",
    "HERE = \"/Users/taliakimber/Documents/github/experiments-binding-affinity/experiments/001_example-ligand-only-graph-subsample\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005009,
     "end_time": "2021-08-09T13:26:11.576426",
     "exception": false,
     "start_time": "2021-08-09T13:26:11.571417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "‚ö† From here on, you should _not_ need to modify anything else ü§û\n",
    "\n",
    "---\n",
    "\n",
    "Define key paths for data and outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T13:26:11.591179Z",
     "iopub.status.busy": "2021-08-09T13:26:11.590604Z",
     "iopub.status.idle": "2021-08-09T13:26:11.593306Z",
     "shell.execute_reply": "2021-08-09T13:26:11.593741Z"
    },
    "papermill": {
     "duration": 0.012788,
     "end_time": "2021-08-09T13:26:11.593904",
     "exception": false,
     "start_time": "2021-08-09T13:26:11.581116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook:           HERE = /Users/taliakimber/Documents/github/experiments-binding-affinity/experiments/001_example-ligand-only-graph-subsample\n",
      "This repo:               REPO = /Users/taliakimber/Documents/github/experiments-binding-affinity\n",
      "Features:      FEATURES_STORE = /Users/taliakimber/Documents/github/experiments-binding-affinity/features\n",
      "Outputs in:               OUT = /Users/taliakimber/Documents/github/experiments-binding-affinity/experiments/001_example-ligand-only-graph-subsample/_output/20210809-152611\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "HERE = Path(HERE)\n",
    "\n",
    "for parent in HERE.parents:\n",
    "    if next(parent.glob(\".github/\"), None):\n",
    "        REPO = parent\n",
    "        break\n",
    "\n",
    "FEATURES_STORE = REPO / \"features\"\n",
    "        \n",
    "OUT = HERE / \"_output\" / datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"This notebook:           HERE = {HERE}\")\n",
    "print(f\"This repo:               REPO = {REPO}\")\n",
    "print(f\"Features:      FEATURES_STORE = {FEATURES_STORE}\")\n",
    "print(f\"Outputs in:               OUT = {OUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T13:26:11.608347Z",
     "iopub.status.busy": "2021-08-09T13:26:11.607812Z",
     "iopub.status.idle": "2021-08-09T13:26:11.609403Z",
     "shell.execute_reply": "2021-08-09T13:26:11.609939Z"
    },
    "papermill": {
     "duration": 0.010199,
     "end_time": "2021-08-09T13:26:11.610097",
     "exception": false,
     "start_time": "2021-08-09T13:26:11.599898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nasty trick: save all-caps local variables (CONSTANTS working as hyperparameters) so far in a dict to save it later\n",
    "_hparams = {key: value for key, value in locals().items() if key.upper() == key and not key.startswith((\"_\", \"OE_\"))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T13:26:11.625013Z",
     "iopub.status.busy": "2021-08-09T13:26:11.624491Z",
     "iopub.status.idle": "2021-08-09T13:26:13.403463Z",
     "shell.execute_reply": "2021-08-09T13:26:13.404067Z"
    },
    "papermill": {
     "duration": 1.789074,
     "end_time": "2021-08-09T13:26:13.404351",
     "exception": false,
     "start_time": "2021-08-09T13:26:11.615277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Unable to load toolkit 'OpenEye Toolkit'. The Open Force Field Toolkit does not require the OpenEye Toolkits, and can use RDKit/AmberTools instead. However, if you have a valid license for the OpenEye Toolkits, consider installing them for faster performance and additional file format support: https://docs.eyesopen.com/toolkits/python/quickstart-python/linuxosx.html OpenEye offers free Toolkit licenses for academics: https://www.eyesopen.com/academic-licensing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run started at 2021-08-09 15:26:13.399298\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from warnings import warn\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from IPython.display import Markdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from tqdm.auto import trange, tqdm\n",
    "\n",
    "from kinoml.ml.torch_loops import LRScheduler, EarlyStopping\n",
    "from kinoml.utils import seed_everything, import_object\n",
    "from kinoml.core import measurements as measurement_types\n",
    "from kinoml.core.measurements import null_observation_model\n",
    "from kinoml.analysis.metrics import performance\n",
    "from kinoml.analysis.plots import predicted_vs_observed\n",
    "\n",
    "# Fix the seed for reproducible random splits -- otherwise we get mixed train/test groups every time, biasing the model evaluation\n",
    "seed_everything();\n",
    "print(\"Run started at\", datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.004873,
     "end_time": "2021-08-09T13:26:13.414290",
     "exception": false,
     "start_time": "2021-08-09T13:26:13.409417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load featurized data and create observation models\n",
    "\n",
    "We assume this path structure: `$REPO/features/_output/<FEATURIZATION>/<DATASET>/<MEASUREMENT_TYPE>.npz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T13:26:13.429950Z",
     "iopub.status.busy": "2021-08-09T13:26:13.429384Z",
     "iopub.status.idle": "2021-08-09T13:26:13.684607Z",
     "shell.execute_reply": "2021-08-09T13:26:13.685071Z"
    },
    "papermill": {
     "duration": 0.266201,
     "end_time": "2021-08-09T13:26:13.685247",
     "exception": false,
     "start_time": "2021-08-09T13:26:13.419046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASETS = []\n",
    "MEASUREMENT_TYPES = set()\n",
    "ParquetLoaderCls = import_object(PARQUET_LOADER_CLS)\n",
    "for glob in PARQUET_FILES:\n",
    "    parquets = list(FEATURES_STORE.glob(glob))\n",
    "    if not parquets:\n",
    "        warn(f\"‚ö† Parquet glob `{glob}` did not match any files!\")\n",
    "        continue\n",
    "        \n",
    "    for parquet in parquets:\n",
    "        measurement_type = parquet.stem\n",
    "        dataset = parquet.parent.name\n",
    "        \n",
    "        ds = ParquetLoaderCls.from_parquet(parquet)\n",
    "        ds.metadata = {\n",
    "            \"dataset\": dataset,\n",
    "            \"measurement_type\": measurement_type,\n",
    "        }\n",
    "        DATASETS.append(ds)\n",
    "        MEASUREMENT_TYPES.add(measurement_type)\n",
    "\n",
    "if not DATASETS:\n",
    "    raise ValueError(\"Provided `PARQUET_FILES` did not result in any valid datasets!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00504,
     "end_time": "2021-08-09T13:26:13.695998",
     "exception": false,
     "start_time": "2021-08-09T13:26:13.690958",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we have all the data-dependent objects, we can start with the model-specific definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T13:26:13.710382Z",
     "iopub.status.busy": "2021-08-09T13:26:13.709752Z",
     "iopub.status.idle": "2021-08-09T13:26:13.712168Z",
     "shell.execute_reply": "2021-08-09T13:26:13.712522Z"
    },
    "papermill": {
     "duration": 0.011814,
     "end_time": "2021-08-09T13:26:13.712737",
     "exception": false,
     "start_time": "2021-08-09T13:26:13.700923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 18 datasets with a total of 100 measurements.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(DATASETS)} datasets with a total of {sum(len(d) for d in DATASETS)} measurements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.004962,
     "end_time": "2021-08-09T13:26:13.722936",
     "exception": false,
     "start_time": "2021-08-09T13:26:13.717974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prepare splits and dataloaders\n",
    "\n",
    "Create train / test / validation subsets. Here we implement a random split, but it can take external indices if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T13:26:13.741236Z",
     "iopub.status.busy": "2021-08-09T13:26:13.740679Z",
     "iopub.status.idle": "2021-08-09T13:26:14.564837Z",
     "shell.execute_reply": "2021-08-09T13:26:14.565215Z"
    },
    "papermill": {
     "duration": 0.837279,
     "end_time": "2021-08-09T13:26:14.565387",
     "exception": false,
     "start_time": "2021-08-09T13:26:13.728108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "for dataset in DATASETS:\n",
    "    key = dataset.metadata[\"measurement_type\"]\n",
    "    \n",
    "    # Generate random indices in situ\n",
    "    # If you need to provide indices from another source, \n",
    "    # replace this block to provide train_indices, test_indices\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(TRAIN_TEST_SPLIT * dataset_size))\n",
    "    \n",
    "    if SHUFFLE_SPLITS :\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, test_indices = indices[split:], indices[split:]\n",
    "    if VALIDATION:\n",
    "        split2 = int(np.floor(len(test_indices) / 2))\n",
    "        test_indices, val_indices = test_indices[:split2], test_indices[split2:]\n",
    "    # End of indices creation\n",
    "    \n",
    "    collate_fn = None\n",
    "    if COLLATE_FN:\n",
    "        # IMPORTANT: This will be needed if your X tensors have different shapes across systems!\n",
    "        # COLLATE_FN can be an import string, or a eval-able lambda\n",
    "        # Read https://pytorch.org/docs/stable/data.html#dataloader-collate-fn\n",
    "        try:\n",
    "            collate_fn = import_object(COLLATE_FN)\n",
    "        except ImportError:\n",
    "            collate_fn = eval(COLLATE_FN)\n",
    "    \n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "    dataloaders[key] = {\n",
    "        \"train\": import_object(DATALOADER_CLS)(dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn),\n",
    "        \"test\": import_object(DATALOADER_CLS)(dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn),\n",
    "    }\n",
    "    \n",
    "    if VALIDATION:\n",
    "        val_sampler = SubsetRandomSampler(val_indices)\n",
    "        dataloaders[key][\"val\"] = import_object(DATALOADER_CLS)(dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005099,
     "end_time": "2021-08-09T13:26:14.576159",
     "exception": false,
     "start_time": "2021-08-09T13:26:14.571060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c4bad8",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T13:26:14.594733Z",
     "iopub.status.busy": "2021-08-09T13:26:14.593991Z",
     "iopub.status.idle": "2021-08-09T13:26:15.231214Z",
     "shell.execute_reply": "2021-08-09T13:26:15.230495Z"
    },
    "papermill": {
     "duration": 0.650304,
     "end_time": "2021-08-09T13:26:15.231468",
     "exception": true,
     "start_time": "2021-08-09T13:26:14.581164",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [2, 50] at entry 0 and [2, 52] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c525cb273784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mModelCls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0ma_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mMODEL_KWARGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_shape\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_input_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/experiments-binding-affinity/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/experiments-binding-affinity/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/experiments-binding-affinity/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/envs/experiments-binding-affinity/lib/python3.8/site-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/experiments-binding-affinity/lib/python3.8/site-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader found invalid type: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/experiments-binding-affinity/lib/python3.8/site-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader found invalid type: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/experiments-binding-affinity/lib/python3.8/site-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader found invalid type: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/experiments-binding-affinity/lib/python3.8/site-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader found invalid type: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/experiments-binding-affinity/lib/python3.8/site-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     17\u001b[0m                                         self.exclude_keys)\n\u001b[1;32m     18\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/experiments-binding-affinity/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [2, 50] at entry 0 and [2, 52] at entry 1"
     ]
    }
   ],
   "source": [
    "ModelCls = import_object(MODEL_CLS)\n",
    "\n",
    "# Note that we assume all dataloaders will provide the\n",
    "# same kind of input shape, so we onlt test on one\n",
    "if ModelCls.needs_input_shape:\n",
    "    a_dataloader = dataloaders[next(iter(dataloaders.keys()))][\"train\"]\n",
    "    x_sample, _ = next(iter(a_dataloader))\n",
    "    MODEL_KWARGS[\"input_shape\"] = ModelCls.estimate_input_shape(x_sample)\n",
    "\n",
    "nn_model = ModelCls(**MODEL_KWARGS)\n",
    "\n",
    "optimizer = import_object(OPTIMIZER)(nn_model.parameters(), **OPTIMIZER_KWARGS)\n",
    "loss_function = import_object(LOSS)()\n",
    "\n",
    "if VALIDATION:\n",
    "    lr_scheduler = LRScheduler(optimizer)\n",
    "    early_stopping = EarlyStopping(**EARLY_STOPPING_KWARGS)\n",
    "\n",
    "train_loss_timeseries = []\n",
    "val_loss_timeseries = []\n",
    "\n",
    "range_epochs = trange(MAX_EPOCHS, desc=\"Epochs\")\n",
    "for epoch in range_epochs:\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    for key, loader in tqdm(dataloaders.items(), desc=\"Datasets\", leave=False):\n",
    "        mtype_class = import_object(f\"kinoml.core.measurements.{key}\")\n",
    "        loss_adapter = mtype_class.loss_adapter(backend=\"pytorch\")\n",
    "        \n",
    "        # TRAIN\n",
    "        nn_model.train()\n",
    "        for x, y in tqdm(loader[\"train\"], desc=\"Minibatches\", leave=False):\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Obtain model prediction given model input\n",
    "            prediction = nn_model(x)\n",
    "            # apply observation model\n",
    "            loss = loss_adapter(prediction.view_as(y), y, loss_function)\n",
    "            # Pred. must match y shape!    ^^^^^^^^^^\n",
    "            # Obtain loss for the predicted output\n",
    "            train_loss += loss.item()\n",
    "            # Gradients w.r.t. parameters\n",
    "            loss.backward()\n",
    "            # Optimize\n",
    "            optimizer.step()\n",
    "            \n",
    "        \n",
    "        # VALIDATE\n",
    "        if VALIDATION:\n",
    "            nn_model.eval()\n",
    "            with torch.no_grad():\n",
    "                for x, y in tqdm(loader[\"val\"], desc=\"Minibatches\", leave=False):\n",
    "                    prediction = nn_model(x).view_as(y)\n",
    "                    loss = loss_adapter(prediction.view_as(y), y, loss_function)\n",
    "                    val_loss += loss.item()\n",
    "                    range_epochs.set_description(f\"Epochs (Avg. val. loss={val_loss / (epoch + 1):.2e})\")\n",
    "    \n",
    "    # LOG LOSSES\n",
    "    train_loss_timeseries.append(train_loss)\n",
    "    \n",
    "    if VALIDATION:\n",
    "        val_loss_timeseries.append(val_loss)\n",
    "\n",
    "        # Adjust training if needed\n",
    "        lr_scheduler(val_loss)\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Save model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(nn_model, OUT / \"nn_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "nn_model.train(False)\n",
    "for key, loader in dataloaders.items():\n",
    "    metrics[key] = {}\n",
    "    display(Markdown(f\"#### {key}\"))\n",
    "    for ttype, dataloader in loader.items():\n",
    "        display(Markdown(f\"##### {ttype}\"))\n",
    "        mtype = import_object(f\"kinoml.core.measurements.{key}\")\n",
    "        obs_model = mtype.observation_model(backend=\"pytorch\")\n",
    "        x, y = dataloader.dataset[dataloader.batch_sampler.sampler.indices]\n",
    "        prediction = obs_model(nn_model(x).view_as(y).detach().numpy())\n",
    "\n",
    "        perf_data = performance(prediction, y, verbose=False)\n",
    "        metrics[key][ttype] = {}\n",
    "        for perfkey, values in perf_data.items():\n",
    "            metrics[key][ttype][perfkey] = {\"mean\": values[0], \"std\": values[1]}\n",
    "        display(predicted_vs_observed(prediction, y, mtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Summary\n",
    "\n",
    "`kinase_metrics` is a nested dictionary with these dimensions:\n",
    "\n",
    "- measurement type\n",
    "- metric\n",
    "- mean & standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "### Configuration \n",
    "\n",
    "```json\n",
    "{json.dumps(_hparams, default=str, indent=2)}\n",
    "```\n",
    "\"\"\"))\n",
    "\n",
    "if VERBOSE:\n",
    "    display(Markdown(\n",
    "f\"\"\"\n",
    "### Kinase metrics\n",
    "\n",
    "```json\n",
    "{json.dumps(metrics, default=str, indent=2)}\n",
    "```\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for mtype_name in MEASUREMENT_TYPES:\n",
    "    mtype_metrics = metrics.get(mtype_name)\n",
    "    if not mtype_metrics:\n",
    "        continue\n",
    "        \n",
    "    display(Markdown(f\"#### {mtype_name}\"))\n",
    "    \n",
    "    # flatten dict a bit: from dict[\"test\"][\"r2\"][\"mean\"] to dict[\"test\"][\"r2_mean\"]\n",
    "    flattened = {}\n",
    "    for ttype, scores in mtype_metrics.items():\n",
    "        flattened[ttype] = {}\n",
    "        for score, stats in scores.items():\n",
    "            for stat, value in stats.items():\n",
    "                flattened[ttype][f\"{score}_{stat}\"] = value\n",
    "        \n",
    "    df = pd.DataFrame.from_dict(flattened, orient=\"index\")\n",
    "    with pd.option_context(\"display.float_format\", \"{:.3f}\".format, \"display.max_rows\", len(df)):\n",
    "        display(\n",
    "            df.style.background_gradient(subset=[\"r2_mean\"], low=0, high=1, vmin=0, vmax=1)\n",
    "              .apply(lambda x: ['font-weight: bold' for v in x], subset=[\"r2_mean\"])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Run finished at\", datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Save reports to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kinoml.utils import watermark\n",
    "w = watermark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "w = watermark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(OUT / \"performance.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, default=str, indent=2)\n",
    "    \n",
    "with open(OUT/ \"watermark.txt\", \"w\") as f:\n",
    "    f.write(cap.stdout)\n",
    "\n",
    "with open(OUT / \"hparams.json\", \"w\") as f:\n",
    "    json.dump(_hparams, f, default=str, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.251995,
   "end_time": "2021-08-09T13:26:16.599423",
   "environment_variables": {},
   "exception": true,
   "input_path": "experiments/torch-train-test-debug-template.ipynb",
   "output_path": "experiments/001_example-ligand-only-graph-subsample/torch-train-test-debug.ipynb",
   "parameters": {
    "BATCH_SIZE": 64,
    "BOOTSTRAP_SAMPLE_RATIO": 1,
    "COLLATE_FN": null,
    "DATALOADER_CLS": "torch_geometric.data.DataLoader",
    "EARLY_STOPPING_KWARGS": {},
    "HERE": "/Users/taliakimber/Documents/github/experiments-binding-affinity/experiments/001_example-ligand-only-graph-subsample",
    "LOSS": "torch.nn.MSELoss",
    "LOSS_KWARGS": {},
    "MAX_EPOCHS": 50,
    "MODEL_CLS": "kinoml.ml.torch_geometric_models.GraphConvolutionNeuralNetwork",
    "MODEL_KWARGS": {},
    "N_BOOTSTRAPS": 1,
    "OPTIMIZER": "torch.optim.Adam",
    "OPTIMIZER_KWARGS": {
     "betas": [
      0.9,
      0.999
     ],
     "eps": 1e-07,
     "lr": 0.001
    },
    "PARQUET_FILES": [
     "ligand-only-graph-subsample/_output/ligand__SmilesToLigandFeaturizer__GraphLigandFeaturizer/ChEMBLDatasetProvider/*.parquet"
    ],
    "SHUFFLE_SPLITS": true,
    "TRAIN_TEST_SPLIT": 0.2,
    "VALIDATION": true,
    "VERBOSE": false
   },
   "start_time": "2021-08-09T13:26:10.347428",
   "version": "2.2.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}